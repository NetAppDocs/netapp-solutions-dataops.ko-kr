---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: 이 섹션에서는 데이터 전송을 위한 NetApp XCP 배포 단계에 대해 설명합니다. 
---
= 배포 단계
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에서는 데이터 전송을 위한 NetApp XCP 배포 단계에 대해 설명합니다.



== 테스트베드 세부 정보

다음 표는 이 배포와 성능 검증에 사용된 테스트 베드의 세부 정보를 제공합니다.

|===
| 솔루션 구성 요소 | 세부 


| XCP 버전 1.7  a| 
* 하나의 Linux 서버 - Linux(RHEL 7.9 또는 RHEL 8)
* 하나의 Windows 서버 - Windows Server 2019 표준




| 소스 볼륨에 대한 NetApp AFF 스토리지 어레이 HA 쌍  a| 
* AFF8080
* NetApp ONTAP 9
* NFS 프로토콜




| 대상 볼륨을 위한 NetApp AFF 스토리지 어레이 HA 쌍  a| 
* AFF A800
* ONTAP 9
* NFS 프로토콜




| 후지쯔 PRIMERGY RX2540 서버 | 각각 다음이 장착되어 있습니다: * 48개 CPU * Intel Xeon * 256GB 물리적 메모리 * 10GbE 듀얼 포트 


| 네트워킹 | 10GbE 
|===


== 배포 단계 - NAS

데이터 전송을 위해 NetApp XCP를 배포하려면 먼저 대상 위치에 XCP 소프트웨어를 설치하고 활성화합니다.  자세한 내용은 다음에서 확인할 수 있습니다. https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP 사용자 가이드"^] .  그러려면 다음 단계를 완료하세요.

. 섹션에 자세히 설명된 대로 전제 조건을 충족합니다.link:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["XCP의 전제 조건."]
. XCP 소프트웨어를 다운로드하세요 https://mysupport.netapp.com/site/products/all/details/netapp-xcp/downloads-tab["NetApp XCP(다운로드) 페이지"^] .
. 다운로드한 XCP tar 파일을 XCP 서버로 복사합니다.
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. tar파일의 tar를 풉니다.
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. 라이센스를 다운로드하세요 https://xcp.netapp.com/license/xcp.xwic%20["https://xcp.netapp.com/license/xcp.xwic"^] XCP 서버로 복사합니다.
. 라이센스를 활성화합니다.
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. 소스 NFS 포트와 대상 NFS 서버를 찾으세요.  기본 포트는 2049입니다.
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. NFS 연결을 확인하세요.  Telnet을 사용하여 NFS 서버 포트에 접속하여 소스와 대상 모두의 NFS 서버를 확인합니다.
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. 카탈로그를 구성합니다.
+
.. NFS 볼륨을 생성하고 XCP 카탈로그에 대한 NFS를 내보냅니다.  XCP 카탈로그에 대한 운영 체제 NFS 내보내기 기능을 활용할 수도 있습니다.
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. NFS 내보내기를 확인하세요.
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. 업데이트 `xcp.ini` .
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. 다음을 사용하여 소스 NAS 내보내기를 찾으세요. `xcp show` .  찾아보세요:
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. (선택 사항) 소스 NAS 데이터를 스캔합니다.
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
소스 NAS 데이터를 스캔하면 데이터 레이아웃을 이해하고 마이그레이션에 대한 잠재적인 문제를 찾는 데 도움이 됩니다.  XCP 스캐닝 작업 시간은 파일 수와 디렉토리 깊이에 비례합니다.  NAS 데이터에 익숙하다면 이 단계를 건너뛸 수 있습니다.

. 에 의해 생성된 보고서를 확인하세요 `xcp scan` .  주로 읽을 수 없는 폴더와 읽을 수 없는 파일을 검색합니다.
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. (선택 사항) inode를 변경합니다.  카탈로그와 대상 볼륨 모두에 대해 inode 개수를 보고 마이그레이션 또는 복사할 파일 개수에 따라 개수를 수정합니다(필요한 경우).
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. 대상 볼륨을 스캔합니다.
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. 소스 및 대상 볼륨 공간을 확인하세요.
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. 다음을 사용하여 소스에서 대상으로 데이터를 복사합니다. `xcp copy` 요약을 확인하세요.
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: 기본적으로 XCP는 데이터를 복사하기 위해 7개의 병렬 프로세스를 생성합니다.  이는 조정 가능합니다.

+

NOTE: NetApp 소스 볼륨을 읽기 전용으로 설정하는 것을 권장합니다.  실시간으로 소스 볼륨은 활성 파일 시스템입니다.  그만큼 `xcp copy` NetApp XCP는 애플리케이션에 의해 지속적으로 변경되는 라이브 소스를 지원하지 않기 때문에 작업이 실패할 수 있습니다.

+
Linux의 경우 XCP Linux가 카탈로그화를 수행하므로 XCP에 인덱스 ID가 필요합니다.

. (선택 사항) 대상 NetApp 볼륨의 inode를 확인합니다.
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. 다음을 사용하여 증분 업데이트를 수행합니다. `xcp sync` .
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
이 문서의 경우 실시간을 시뮬레이션하기 위해 소스 데이터의 백만 개 파일 이름을 변경한 다음 업데이트된 파일을 사용하여 대상에 복사했습니다. `xcp sync` .  Windows의 경우 XCP에는 소스 경로와 대상 경로가 모두 필요합니다.

. 데이터 전송을 검증합니다.  다음을 사용하여 소스와 대상에 동일한 데이터가 있는지 확인할 수 있습니다. `xcp verify` .
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


XCP 문서에는 여러 옵션(예제 포함)이 제공됩니다. `scan` , `copy` , `sync` , 그리고 `verify` 운영.  자세한 내용은 다음을 참조하세요. https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP 사용자 가이드"^] .


NOTE: Windows 고객은 액세스 제어 목록(ACL)을 사용하여 데이터를 복사해야 합니다.  NetApp 다음 명령을 사용할 것을 권장합니다. `xcp copy -acl -fallbackuser\<username> -fallbackgroup\<username or groupname> <source> <destination>` .  최대 성능을 위해서는 ACL이 있는 SMB 데이터가 있는 소스 볼륨과 NFS와 SMB에서 모두 액세스할 수 있는 데이터를 고려할 때 대상은 NTFS 볼륨이어야 합니다.  XCP(NFS 버전)를 사용하여 Linux 서버에서 데이터를 복사하고 XCP(SMB 버전) 동기화를 실행합니다. `-acl` 그리고 `-nodata` Windows 서버에서 소스 데이터의 ACL을 대상 SMB 데이터로 복사하는 옵션입니다.

자세한 단계는 다음을 참조하세요. https://helpcenter.netwrix.com/NA/Configure_IT_Infrastructure/Accounts/DCA_Manage_Auditing_Security_Log.html["'감사 및 보안 로그 관리' 정책 구성"^] .



== 배포 단계 - HDFS/MapRFS 데이터 마이그레이션

이 섹션에서는 HDFS/MapRFS에서 NFS로, 그리고 그 반대로 데이터를 마이그레이션하는 Hadoop 파일 시스템 데이터를 NAS로 전송하는 새로운 XCP 기능에 대해 설명합니다.



=== 필수 조건

MapRFS/HDFS 기능의 경우 루트가 아닌 사용자 환경에서 다음 절차를 수행해야 합니다.  일반적으로 루트가 아닌 사용자는 hdfs, mapr 또는 HDFS 및 MapRFS 파일 시스템을 변경할 수 있는 권한이 있는 사용자입니다.

. CLI 또는 사용자의 .bashrc 파일에서 CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH 및 NHDFS_LIBHDFS_PATH 변수를 다음과 같이 설정합니다. `xcp` 명령.
+
** NHDFS_LIBHDFS_PATH는 libhdfs.so 파일을 가리킵니다.  이 파일은 Hadoop 배포판의 일부로 HDFS/MapRFS 파일과 파일 시스템과 상호 작용하고 조작할 수 있는 HDFS API를 제공합니다.
** NHDFS_LIBJVM_PATH는 libjvm.so 파일을 가리킵니다.  이는 jre 위치에 있는 공유 JAVA 가상 머신 라이브러리입니다.
** CLASSPATH는 (Hadoop classpath –glob) 값을 사용하여 모든 jar 파일을 가리킵니다.
** LD_LIBRARY_PATH는 Hadoop 기본 라이브러리 폴더 위치를 가리킵니다.
+
다음 샘플은 Cloudera 클러스터를 기반으로 합니다.

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
이번 릴리스에서는 XCP 스캔, 복사, 확인 작업과 HDFS에서 NFS로의 데이터 마이그레이션을 지원합니다.  데이터 레이크 클러스터에서 단일 워커 노드와 여러 워커 노드로 데이터를 전송할 수 있습니다.  1.8 릴리스에서는 루트 사용자와 루트가 아닌 사용자가 데이터 마이그레이션을 수행할 수 있습니다.







=== 배포 단계 - 루트가 아닌 사용자가 HDFS/MaprFS 데이터를 NetApp NFS로 마이그레이션합니다.

. 배포 섹션의 단계 1~9에 언급된 것과 동일한 단계를 따르세요.
. 다음 예에서는 사용자가 HDFS에서 NFS로 데이터를 마이그레이션합니다.
+
.. 폴더와 파일을 만듭니다(사용 `hadoop fs -copyFromLocal` ) HDFS에서.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. HDFS 폴더의 권한을 확인하세요.
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. NFS에 폴더를 만들고 권한을 확인하세요.
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. XCP를 사용하여 HDFS에서 NFS로 파일을 복사하고 권한을 확인합니다.
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----



